<!DOCTYPE html>
<html>
  <head>
    <title>Heteroscedasticidade</title>
    <meta charset="utf-8">
    <meta name="author" content="Luiz Fernando Palin Droubi" />
    <meta name="author" content="Willian Zonato" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link rel="stylesheet" href="estilo.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Heteroscedasticidade
## Causas, detecção e consequências
### Luiz Fernando Palin Droubi
### Willian Zonato
### 17/10/2018

---




background-image: url(images/logs-1.png)

---
class: inverse, center, middle

# MÍNIMOS QUADRADOS ORDINÁRIOS

---

### MÍNIMOS QUADRADOS ORDINÁRIOS

#### Definição

A equação de regressão linear é uma equação para a *média condicional* da variável
dependente em função dos regressores.

--

- `$$\mu(t) = \mathbb{E} [Y|X=t]$$`


--

em que:

- `\(\mu\)` é a *média*
- `\(\mu(t)\)` é a *média condicional*

---
class: center

### MÍNIMOS QUADRADOS ORDINÁRIOS

![](Apresentacao_files/figure-html/explicacao_grafica-1.svg)&lt;!-- --&gt;


---
### MÍNIMOS QUADRADOS ORDINÁRIOS

Por definição, a regressão linear é uma minimização do erro médio quadrático:

`$$\mathbb{E}(y|x) = \alpha + x \beta$$`
--

`$$y = \alpha + x \beta + \epsilon$$`

--
`$$\epsilon = y - \mathbb{E}(y|x)$$`
--

Para calcularmos os valores de `\(\alpha\)` e `\(\beta\)`, na regressão linear ordinária, fazemos:

`$$argmin(S = \sum_{t=1}^T \epsilon_t^2)$$`

---
class: inverse, center, middle

# CÁLCULO DOS PARÂMETROS

---

### MÍNIMOS QUADRADOS ORDINÁRIOS

--

`$$\frac{\partial S}{\partial \alpha} = 0 \rightarrow \hat{\alpha} = \bar{y} - \beta \bar{x}$$`
--

`$$\frac{\partial S}{\partial \beta} = 0 \rightarrow \hat{\beta} = \frac{\sum x_t y_t - T \bar{x}\bar{y}}{\sum{x_t^2 - T\bar{x}^2}}$$`
--

- `\(\hat{\beta}\)` é aproximadamente normal e não-enviesado mesmo na ausência da
homoscedasticidade e da normalidade (TLC).

---

### MÍNIMOS QUADRADOS ORDINÁRIOS

#### Formulação Matricial

--

`$$\hat{\beta} = (A'A)^{-1}A'D$$`
--

onde:

--

* `\(A\)` é a matriz dos regressores, adicionada de uma primeira coluna com todos os 
valores iguais a 1.

--

* `\(D\)` é o vetor dos valores observados da variável dependente

--

* Homocedasticidade: `\(Cov(D|A) = \sigma^2I\)`


---

### MÍNIMOS QUADRADOS ORDINÁRIOS

#### Variância condicional

--

Analogamente, pode-se escrever uma equação para a variância condicional:

`$$\sigma^2(t) = \text{Var}[Y|X=t]$$`
--

No métodos dos MQO, `\(\sigma^2(t) = k\)`

---
class: inverse, center, middle

# MATRIZ DE VARIÂNCIA-COVARIÂNCIA

---

### MÍNIMOS QUADRADOS ORDINÁRIOS

A matriz de variância-covariância pode ser escrita como abaixo:

$$
`\begin{bmatrix}
\text{var}(\epsilon_1) &amp; \text{cov}(\epsilon_1 \epsilon_2) &amp; \cdots  &amp; \text{cov}(\epsilon_1 \epsilon_T)\\ \text{cov}(\epsilon_1 \epsilon_2) &amp; \text{var}(\epsilon_2) &amp;  \cdots &amp; \text{cov}(\epsilon_2 \epsilon_T)\\ \vdots &amp;  \vdots &amp; \ddots  &amp; \\ 
\text{cov}(\epsilon_1 \epsilon_T) &amp; \text{cov}(\epsilon_2 \epsilon_T) &amp;  &amp;\text{var}(\epsilon_T) 
\end{bmatrix}`
$$

--

No método dos MQO:

$$
`\begin{bmatrix}
\sigma^2 &amp; 0 &amp; \cdots  &amp; 0 \\ 
0 &amp; \sigma^2 &amp;  \cdots &amp; 0\\ 
\vdots &amp;  \vdots &amp; \ddots  &amp; \\ 
0 &amp; 0 &amp;  &amp; \sigma^2 
\end{bmatrix}`
= \sigma^2I
$$
--

* `\(\sigma^2\)` é um parâmetro da **população** e precisa ser estimado.

--

* `$$s^2(A'A)^{-1}$$`

--

* `\(s^2 = \frac{1}{n-p-1}\sum_{i=1}^n (Y_i - \tilde{X}'_i\hat{\beta})^2\)`
---
class: inverse, center, middle

# MÍNIMOS QUADRADOS PONDERADOS

---

### MÍNIMOS QUADRADOS PONDERADOS

A regressão linear ponderada nada mais é do que a minimização do erro médio
quadrático *ponderado* por pesos pré-estabelecidos para cada observação:

`$$argmin(\sum_{t=1}^T \frac{1}{w_t}\epsilon_t^2)$$`

--

- `\(w_t\)` são os pesos da ponderação

--

- No MQO, `\(w_1 = w_2 = \cdots = w_T = 1\)`

---
class: inverse, center, middle

# MÍNIMOS QUADRADOS GENERALIZADOS

---
class: inverse, center, middle

# HETEROSCEDASTICIDADE

---

### HETEROSCEDASTICIDADE

- A hipótese da Homoscedasticidade é:

`$$\sigma^2(t) = \text{k} \forall \text{t} \in \mathbb{R}$$`
--

- A Heteroscedasticidade é o inverso da Homoscedasticidade, ou seja:

`$$\text{Var}(Y|X=t) \neq k$$`

---
class: inverse, center, middle

# CAUSAS DA HETEROSCEDASTICIDADE

---

### HETEROSCEDASTICIDADE

#### CAUSAS

A heteroscedasticidade pode advir de problemas de má-especificação do modelo 
(falta de variáveis importantes), transformações inadequadas, presença de 
subpopulações dentro da amostra (interação)


---
class: inverse, center, middle

# CONSEQUÊNCIAS DA HETEROSCEDASTICIDADE

---

### HETEROSCEDASTICIDADE

#### CONSEQUÊNCIAS

--
- `\(\hat{\beta_i}\)` é não-enviesado, consistente e assintoticamente normal mesmo
sem a verificação da normalidade ou da homoscedasticidade.

--

- Contudo, `\(\hat{\beta_i}\)` não são **BLUE** na presença de heteroscedasticidade. 
Isto é: entre todos os estimadores não-enviesados, `\(\hat{\beta_i}\)` não serão os
de menor variância.

--

- Ou seja, não há viés, não há inconsistência, mas há perda de **eficiência**
na heteroscedasticidade.

--

- Os procedimentos da inferência estatística padrão assumem a 
homoscedasticidade.

--

- Ou seja, a heteroscedasticidade não invalida os valores dos `\(\hat{\beta_i}\)`, 
porém invalida os procedimentos normalmente adotados na inferência estatística
para o cálculo dos intervalos de confiança e os testes de significância.

---
class: inverse, center, middle

# TIPOS DE HETEROSCEDASTICIDADE

---

### HETEROSCEDASTICIDADE

#### TIPOS

--

- Assim como existem várias causas para a heteroscedasticidade, existem vários
tipos de heteroscedasticidade.

--

- Ou seja, `\(\sigma^2(t)\)` pode ser uma função linear ou não-linear.

---
class: inverse, center, middle

# TESTES DE HETEROSCEDASTICIDADE

---

### HETEROSCEDASTICIDADE

#### TESTES

--

- Não existe o melhor teste, mas o teste mais apropriado para cada tipo de 
heteroscedasticidade.

--

- O teste de Breusch-Pagan detecta formas lineares de heteroscedasticidade.

--

- O teste de White é um caso particular do teste de Breusch-Pagan, que leva
em consideração os termos quadráticos e os termos de interação entre as 
variáveis independentes.

---
class: inverse, center, middle

# EXEMPLOS

---
### HETEROSCEDASTICIDADE

#### Exemplo 1

![](Apresentacao_files/figure-html/hetero-1.svg)&lt;!-- --&gt;


---

### HETEROSCEDASTICIDADE

#### Exemplo 1

##### Teste de Breusch-Pagan


```r
bptest(fit)
```

```
## 
## 	studentized Breusch-Pagan test
## 
## data:  fit
## BP = 27.715, df = 1, p-value = 1.405e-07
```


--


```r
aux_lm &lt;- lm(resid(fit)^2 ~ X)
s &lt;- summary(aux_lm)
bp_stat &lt;- length(resid(fit)^2)*s$r.squared
p_valor &lt;- pchisq(bp_stat, 1, lower.tail = FALSE)
```


```
## [1] 27.71526
```

```
## [1] 1.405498e-07
```

---

### HETEROSCEDASTICIDADE

#### Exemplo 2

![](Apresentacao_files/figure-html/hetero2-1.svg)&lt;!-- --&gt;


---

### HETEROSCEDASTICIDADE

#### Exemplo 2

##### Teste de Breusch-Pagan


```r
bptest(fit2)
```

```
## 
## 	studentized Breusch-Pagan test
## 
## data:  fit2
## BP = 31.59, df = 1, p-value = 1.904e-08
```

---

### HETEROSCEDASTICIDADE

#### Exemplo 3

![](Apresentacao_files/figure-html/hetero3-1.svg)&lt;!-- --&gt;

---

### HETEROSCEDASTICIDADE

#### Exemplo 3

##### Teste de Breusch-Pagan


```r
bptest(fit3)
```

```
## 
## 	studentized Breusch-Pagan test
## 
## data:  fit3
## BP = 0.021291, df = 1, p-value = 0.884
```

--

##### Teste de White


```r
bptest(fit3, ~X + I(X^2))
```

```
## 
## 	studentized Breusch-Pagan test
## 
## data:  fit3
## BP = 50.283, df = 2, p-value = 1.205e-11
```

---
class: inverse, center, middle

# CONTORNANDO A HETEROSCEDASTICIDADE

---

### CONTORNANDO A HETEROSCEDASTICIDADE

#### Erros heteroscedástico-consistentes 

--

* `\(\frac{1}{n}[E(XX')]^{-1}E[\epsilon XX'][E(XX')]^{-1}\)`

--

* **Estimadores Sanduíche**

--

* Eicker-White 

`$$Var(\hat\beta) = (X'X)^{-1}(\sum_{t=1}^T \hat{\epsilon}^2_t x_t x_t')(X'X)^{-1}$$`

--
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script>
(function() {
  var i, text, code, codes = document.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
})();
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
